

# Items

# 💻 Tarea 2 - Computación Cuántica

---

### 📌 1. ¿Qué es la Computación Cuántica?
La **computación cuántica** es un paradigma de la informática que utiliza los principios de la **mecánica cuántica** para procesar información.  
A diferencia de la computación clásica (basada en bits 0 y 1), la cuántica emplea **qubits**, que pueden estar en **superposición** de estados.

🔑 Características principales:
- **Superposición**: los qubits pueden ser 0 y 1 al mismo tiempo.  
- **Entrelazamiento**: correlación entre qubits aunque estén separados físicamente.  
- **Interferencia cuántica**: refuerza las soluciones correctas y cancela las incorrectas.  
- **Medición probabilística**: los resultados se obtienen con cierta probabilidad.  
---
### 📌  Arquitectura de un Computador Cuántico
Un computador cuántico está compuesto por varias partes fundamentales:

1. **Qubits** → unidad básica de información cuántica.  
2. **Puertas cuánticas** → operaciones que modifican el estado de los qubits (Hadamard, CNOT, Pauli-X).  
3. **Sistema de control** → microondas, láseres o campos magnéticos que manipulan los qubits.  
4. **Criogenia** → mantiene el sistema a temperaturas cercanas al **cero absoluto (-273 °C)**.  
5. **Interfaz clásica** → traduce las instrucciones del usuario en operaciones cuánticas.
6. 


*Figura 1. Representación gráfica de un procesador cuántico.*



---
### 📌  Historia de la Computación Cuántica

- **1981**: Richard Feynman propone simular sistemas cuánticos con computadoras.  
- **1985**: David Deutsch define el concepto de **computadora cuántica universal**.  
- **1994**: Peter Shor crea un algoritmo cuántico para la factorización eficiente.  
- **2001**: IBM ejecuta el algoritmo de Shor con 7 qubits.  
- **2019**: Google anuncia la "supremacía cuántica" con su procesador *Sycamore*.  

### ✅ Ventajas
- Alta velocidad en factorización y problemas criptográficos.  
- Simulación precisa de sistemas cuánticos.  
- Resolución de problemas de optimización.  

### ❌ Desventajas
- Sensibilidad a la **decoherencia** (ruido externo).  
- Requiere temperaturas extremadamente bajas.  
- Tecnología aún en desarrollo (limitada a laboratorios).  

---

### 📌  Conceptos Fundamentales

🔹 **Superposición** → permite que un qubit represente múltiples estados a la vez.  
🔹 **Entrelazamiento** → genera correlación instantánea entre qubits.  
🔹 **Interferencia Cuántica** → mecanismo para optimizar soluciones.  
🔹 **Medición probabilística** → el estado final se obtiene con cierta probabilidad.  
🔹 **Decoherencia** → pérdida de información cuántica por el entorno.  
🔹 **Puertas cuánticas** → análogas a las lógicas clásicas, pero con operaciones cuánticas.  

Ejemplos:
- **Hadamard (H)**: crea superposición.  
- **CNOT**: entrelaza dos qubits.  
- **Pauli-X**: equivalente a un NOT clásico.  

---

## 📌  Referencias

- Nielsen, M. A., & Chuang, I. L. (2010). *Quantum Computation and Quantum Information*. Cambridge University Press.  
- IBM Quantum Experience → [https://quantum-computing.ibm.com/](https://quantum-computing.ibm.com/)  
- Google Quantum AI → [https://quantumai.google/](https://quantumai.google/)  
- Preskill, J. (2018). *Quantum Computing in the NISQ era and beyond*.  

---
# 2. Computación Neuromórfica
---

## 📌 ¿Qué es un computador neuromórfico?
Un **computador neuromórfico** es un sistema diseñado para imitar el funcionamiento del cerebro humano, utilizando redes de **neuronas artificiales** implementadas en hardware especializado.  
Estos sistemas están enfocados en tareas como:
- Aprendizaje automático.
- <p align="center">
  <img width="400" height="600" alt="image" src="https://github.com/user-attachments/assets/91b4442b-9350-4bcd-b8a3-2f7da8a87c27" />
</p>

- Reconocimiento de patrones.  
- Procesamiento en paralelo.  
- Visión artificial e inteligencia artificial.  

---

## 🏗️ Arquitectura de un computador neuromórfico
La arquitectura neuromórfica se basa en **unidades de procesamiento que actúan como neuronas** y se interconectan a través de sinapsis simuladas.  

### 🔹 Ventajas
- Bajo consumo energético.  
- Procesamiento paralelo masivo.  
- Mayor eficiencia en tareas de IA.

### 🔹 Desventajas
- Complejidad en la programación.  
- Aún está en fase de investigación.  
- Costos elevados de desarrollo.
- 


---

## ⚙️ Hardware utilizado en la computación neuromórfica
Existen distintos chips y plataformas diseñadas específicamente:

- **IBM TrueNorth** → 1 millón de neuronas y 256 millones de sinapsis.  
- **Intel Loihi** → procesador neuromórfico con aprendizaje en tiempo real.  
- **SpiNNaker (University of Manchester)** → simula millones de neuronas biológicas.  

Ejemplo de un **chip neuromórfico**:  
![Chip neuromórfico](https://newsimg.bbc.co.uk/media/images/48118000/jpg/_48118372_chip.jpg)

---

## 🔎 Tipos de computación neuromórfica
1. **Basada en hardware especializado** (chips neuromórficos).  
2. **Basada en software** que simula redes neuronales en sistemas convencionales.  
3. **Híbrida** (combinación de hardware y software).  

---

## 📚 Referencias
- IBM Research. (2014). *TrueNorth Neurosynaptic System*. Disponible en: https://research.ibm.com  
- Intel Labs. (2018). *Loihi: Intel’s Neuromorphic Research Chip*. Disponible en: https://www.intel.com  
- Wikipedia. (2023). *Computación neuromórfica*. Disponible en: https://es.wikipedia.org/wiki/Computaci%C3%B3n_neurom%C3%B3rfica  
- BBC News. (2011). *Brain-inspired computer chips*. Disponible en: https://www.bbc.com  


# 3. Ordenadores Biológicos  

## 📌 ¿Qué es un ordenador biológico?  
Un ordenador biológico es un sistema de procesamiento que utiliza moléculas biológicas (ADN, ARN, proteínas o células vivas) para realizar cálculos en lugar de circuitos electrónicos.  

## 🏗️ Arquitectura  
- **Entrada:** Moléculas biológicas.  
- **Procesamiento:** Reacciones bioquímicas (puertas lógicas biológicas).  
- **Salida:** Cambios moleculares observables.  

## 🔬 Tipos de ordenadores biológicos  
1. Computadores de ADN.  
2. Computadores celulares.  
3. Computadores de proteínas.  

## 🕒 Hitos principales  
- 1994: Primer computador de ADN por Leonard Adleman.  
- 2002: Puertas lógicas con ADN (Microsoft Research).  
- 2013: Células programadas como circuitos lógicos (Stanford).  
- 2017–actualidad: Avances en biología sintética.  

## 📷 Imágenes  
![Ejemplo Computador ADN](https://upload.wikimedia.org/wikipedia/commons/1/1d/DNA_double_helix_horizontal.png)

## 📚 Referencias  
- Adleman, L. (1994). Molecular computation of solutions to combinatorial problems. *Science*.  
- Amos, M. (2019). Theoretical and Experimental DNA Computation. Springer.  
- Stanford University (2013). Synthetic biology milestones.  

---
# 4. 🖥️ Arquitectura de Computación Heterogénea

## 📌 ¿Qué es?
La **computación heterogénea** es un modelo de arquitectura en el cual se utilizan diferentes tipos de procesadores y aceleradores dentro de un mismo sistema para ejecutar tareas específicas de manera más eficiente.  
Por ejemplo: **CPU + GPU + FPGA + DSP**, donde cada uno resuelve partes de un problema según sus fortalezas.

<img src="img/heterogenea.png" alt="Computación Heterogénea" width="500"/>

---

## 🕒 Historia
- **Década de 2000**: uso de GPU como coprocesadores para acelerar gráficos.
- **2006 en adelante**: aparición de **CUDA (NVIDIA)** y **OpenCL**, permitiendo aprovechar GPUs para cómputo científico.
- **2010s**: integración de **SoC heterogéneos** (CPU + GPU en un chip).
- **Actualidad**: uso en inteligencia artificial, Big Data, simulaciones científicas y dispositivos móviles.

---

## ✅ Ventajas
- Mejor rendimiento al aprovechar cada procesador según la tarea.
- Mayor eficiencia energética.
- Escalabilidad en aplicaciones científicas y de IA.
- Reducción de costos al optimizar recursos.

<img src="img/ventajas.png" alt="Ventajas" width="400"/>

---

## ❌ Desventajas
- Complejidad en la programación.
- Mayor dificultad en la optimización del software.
- Dependencia de frameworks específicos (CUDA, OpenCL).
- Problemas de compatibilidad entre hardware heterogéneo.

<img src="img/desventajas.png" alt="Desventajas" width="400"/>

---

## 📚 Referencias
- Hennessy, J. & Patterson, D. (2018). *Computer Architecture: A Quantitative Approach*. Morgan Kaufmann.
- NVIDIA. [CUDA Toolkit Documentation](https://docs.nvidia.com/cuda/).
- Khronos Group. [OpenCL Overview](https://www.khronos.org/opencl/).

---
# 🖥️ Computación en el Borde

## 📌 ¿Qué es la computación de borde?
La **computación de borde (Edge Computing)** es un paradigma de computación distribuida que acerca el procesamiento de datos a la ubicación donde estos se generan (sensores, dispositivos IoT, cámaras, etc.), en lugar de depender únicamente de un servidor central o la nube.  
De esta forma, se reducen los tiempos de respuesta y el consumo de ancho de banda.

---

## 📖 Historia
- **Años 1990-2000**: el modelo tradicional estaba basado en servidores centrales y *cloud computing*.  
- **2006**: con la popularización de servicios en la nube (ejemplo: Amazon Web Services), el tráfico de datos creció exponencialmente.  
- **2010 en adelante**: surge la necesidad de **procesar datos más cerca de la fuente** (IoT, automóviles inteligentes, salud en tiempo real).  
- **Hoy**: la computación en el borde se integra con **IA, 5G y Big Data** para mejorar eficiencia y seguridad.

---

## ✅ Ventajas
- **Menor latencia**: respuestas rápidas en tiempo real.  
- **Optimización del ancho de banda**: menos datos enviados a la nube.  
- **Mayor seguridad**: parte de los datos se procesan localmente, reduciendo vulnerabilidades.  
- **Confiabilidad**: funciona incluso con conexiones intermitentes a internet.

---

## ❌ Desventajas
- **Costos iniciales altos**: requiere hardware distribuido.  
- **Mantenimiento complejo**: más nodos que supervisar.  
- **Escalabilidad limitada** en comparación con la nube.  
- **Riesgo de seguridad física**: los dispositivos en campo pueden ser vulnerables.

---

## 📊 Ejemplo gráfico
![Arquitectura de Edge Computing](https://upload.wikimedia.org/wikipedia/commons/3/3b/Edge-computing-diagram.png)

---

## 📚 Referencias
- OpenFog Consortium. *Edge Computing Reference Architecture*. 2017.  
- Satyanarayanan, M. *The Emergence of Edge Computing*. Computer, IEEE, 2017.  
- IBM Cloud: [¿Qué es la computación de borde?](https://www.ibm.com/mx-es/cloud/what-is-edge-computing)  
- Cisco: [Understanding Edge Computing](https://www.cisco.com/c/en/us/solutions/what-is-edge-computing.html)  


